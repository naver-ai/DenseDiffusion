{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1731b095",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Please refer to the following page for instructions on how to use this evaluation code.\n",
    "# https://github.com/naver-ai/DenseDiffusion/issues/16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "failing-secret",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import yaml\n",
    "import pickle\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "\n",
    "from utils.general import non_max_suppression_mask_conf\n",
    "\n",
    "from detectron2.modeling.poolers import ROIPooler\n",
    "from detectron2.structures import Boxes\n",
    "from detectron2.utils.memory import retry_if_cuda_oom\n",
    "from detectron2.layers import paste_masks_in_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sixth-universe",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "with open('data/hyp.scratch.mask.yaml') as f:\n",
    "    hyp = yaml.load(f, Loader=yaml.FullLoader)\n",
    "weigths = torch.load('yolov7-mask.pt')\n",
    "model = weigths['model']\n",
    "model = model.half().eval().to(device)\n",
    "\n",
    "with open('../dataset/testset_instances.pkl', 'rb') as f:\n",
    "    inst_gt = pickle.load(f) \n",
    "    \n",
    "trans = transforms.Compose([transforms.Resize(224), \n",
    "                            transforms.CenterCrop(224),\n",
    "                            transforms.ToTensor()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6095e65c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "iou = []\n",
    "\n",
    "for i in range(len(inst_gt)):\n",
    "    \n",
    "    # preprocess\n",
    "    im_path = os.path.join('../samples/ours/', str(i)+'.png')\n",
    "    cls_gt = inst_gt[i]['cls_gt']\n",
    "    mask_gt = inst_gt[i]['mask_gt']\n",
    "\n",
    "    image = trans(Image.open(im_path)).unsqueeze(0)\n",
    "    image = image.half().to(device)\n",
    "    \n",
    "    # predict instance masks and classes\n",
    "    output = model(image)\n",
    "    inf_out, attn, bases, sem_output = output['test'], output['attn'], output['bases'], output['sem']\n",
    "    bases = torch.cat([bases, sem_output], dim=1)\n",
    "    nb, _, height, width = image.shape\n",
    "    names = model.names\n",
    "    pooler_scale = model.pooler_scale\n",
    "    pooler = ROIPooler(output_size=hyp['mask_resolution'], scales=(pooler_scale,), sampling_ratio=1,\\\n",
    "                       pooler_type='ROIAlignV2', canonical_level=2)\n",
    "\n",
    "    output, output_mask, output_mask_score, _, _ = non_max_suppression_mask_conf(inf_out, attn, bases, pooler, hyp,\n",
    "                                                                                 conf_thres=0.5, iou_thres=0.65,\n",
    "                                                                                 merge=False, mask_iou=None)\n",
    "    pred, mask_pred = output[0], output_mask[0]\n",
    "    base = bases[0]\n",
    "    if pred == None:\n",
    "        iou.append(0)\n",
    "        continue\n",
    "    \n",
    "    bboxes = Boxes(pred[:, :4])\n",
    "    original_mask_pred = mask_pred.view(-1, hyp['mask_resolution'], hyp['mask_resolution'])\n",
    "    mask_pred = retry_if_cuda_oom(paste_masks_in_image)(original_mask_pred, bboxes, (height, width), threshold=0.5)\n",
    "    mask_pred = F.interpolate(mask_pred.float().unsqueeze(1),(64,64),\n",
    "                              mode='bicubic',align_corners=False).squeeze(1).detach().cpu().numpy()\n",
    "    cls_pred = pred[:, 5].detach().cpu().numpy()\n",
    "    cls_txt_pred = [names[int(p)] for p in cls_pred]\n",
    "    pred_conf = pred[:, 4].detach().cpu().numpy()\n",
    "    \n",
    "    # calculate iou (recall)\n",
    "    cur_iou = []\n",
    "    for p in range(len(cls_gt)):\n",
    "        if cls_gt[p] in cls_txt_pred:\n",
    "            curidx = cls_txt_pred.index(cls_gt[p])\n",
    "            intersection = np.logical_and(mask_gt[p], mask_pred[curidx])\n",
    "            union = np.logical_or(mask_gt[p], mask_pred[curidx])\n",
    "            cur_iou.append(np.sum(intersection) / np.sum(union))\n",
    "            del cls_txt_pred[curidx]\n",
    "            mask_pred = np.concatenate([mask_pred[:curidx,:,:], mask_pred[curidx+1:,:,:]], 0)\n",
    "        else:\n",
    "            cur_iou.append(0)\n",
    "    iou.append(np.mean(cur_iou))\n",
    "    \n",
    "print(np.mean(iou))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b527fa06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33260b6a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ldm2",
   "language": "python",
   "name": "ldm2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
